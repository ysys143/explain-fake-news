{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use base Python 3.12.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from transformers import ElectraModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hw/9m3g7fvn4_l3rp2y473km9sm0000gn/T/ipykernel_49384/3869574122.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_state_dict = torch.load(pretrained_path, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "class KOTESentimentTagger(nn.Module):\n",
    "    def __init__(self, pretrained_path):\n",
    "        super().__init__()\n",
    "        self.electra = ElectraModel.from_pretrained(\"beomi/KcELECTRA-base\", revision='v2021')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\", revision='v2021')\n",
    "        self.intermediate_classifier = nn.Linear(self.electra.config.hidden_size, 44)\n",
    "        self.final_classifier = nn.Linear(44, 3)  # 3-class 분류\n",
    "        self.n_classes = 3\n",
    "\n",
    "        # Pretrained 가중치 로드\n",
    "        pretrained_state_dict = torch.load(pretrained_path, map_location=torch.device('cpu'))\n",
    "        self.load_state_dict(pretrained_state_dict, strict=False)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.electra(input_ids, attention_mask=attention_mask)\n",
    "        output = output.last_hidden_state[:, 0, :]  # (batch_size, 768)\n",
    "        intermediate_output = self.intermediate_classifier(output)  # (batch_size, 44)\n",
    "        output = self.final_classifier(intermediate_output)  # (batch_size, 3)\n",
    "        return output\n",
    "\n",
    "\n",
    "# 모델 경로와 데이터 설정\n",
    "trained_path = \"/Users/jaesolshin/Documents/GitHub/youtube_dashboard/kote_finetuned_model.bin\"\n",
    "input_file = \"/Users/jaesolshin/Documents/GitHub/youtube_dashboard/quota_sample_1000.csv\"\n",
    "\n",
    "# 모델 초기화 및 데이터 로드\n",
    "model = KOTESentimentTagger(trained_path).to(device)\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# 테스트할 샘플 인덱스\n",
    "sample_indices = [0, 20, 668, 790]\n",
    "\n",
    "# 샘플 데이터 가져오기\n",
    "sample_data = data.iloc[sample_indices]\n",
    "comments = sample_data['comment'].tolist()\n",
    "labels = sample_data['sentiment'].tolist()\n",
    "\n",
    "# 토큰화 및 모델 입력 준비\n",
    "encodings = model.tokenizer.batch_encode_plus(\n",
    "    comments,\n",
    "    add_special_tokens=True,\n",
    "    max_length=512,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    "    )\n",
    "\n",
    "inputs = encodings['input_ids'].to(device)\n",
    "attention_mask = encodings['attention_mask'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape torch.Size([4, 512])\n",
      "outputs.shape torch.Size([4, 3])\n",
      "labels [0, 2, 0, 0]\n",
      "preds [2, 2, 0, 0]\n",
      "softmaxs [[0.014299365691840649, 0.019387319684028625, 0.966313362121582], [0.011146849021315575, 0.017465872690081596, 0.9713872671127319], [0.9796472787857056, 0.011131585575640202, 0.00922112911939621], [0.9549960494041443, 0.015010247007012367, 0.0299936942756176]]\n"
     ]
    }
   ],
   "source": [
    "# 추론\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs, attention_mask)\n",
    "    softmaxs = nn.Softmax(dim=1)(outputs)\n",
    "    preds = torch.argmax(softmaxs, dim=1)\n",
    "\n",
    "# 출력 결과\n",
    "print('inputs.shape', inputs.shape)\n",
    "print('outputs.shape', outputs.shape)\n",
    "print('labels', labels)\n",
    "print('preds', preds.tolist())\n",
    "print('softmaxs', softmaxs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "    Comment: 뮤비 다이렉터와 코디... 컨셉 잡기 전 노래 들어본거 맞지?요즘 하이틴 감성 노래와 춤에다가 갑자기 중세시대 옷 그리고 군복.. 언밸러스 매력?ㅋㅋㅋ\n",
      "    True Label: 0\n",
      "    Prediction (KcELECTRA): 2\n",
      "    Confidence Score (softmax): 0.9663\n",
      "    \n",
      "==================================================\n",
      "\n",
      "    Comment: 이 MV는 완벽합니다\n",
      "    True Label: 2\n",
      "    Prediction (KcELECTRA): 2\n",
      "    Confidence Score (softmax): 0.9714\n",
      "    \n",
      "==================================================\n",
      "\n",
      "    Comment: 친북 친중하고 예수 찬양하는 놈들이 친일이랑 단월드를 욕할 자격은 있고? 내가 보기엔 둘 다 똑같은데? ㅋㅋㅋㅋㅋ 친북 친중 친일도 정신병자들이고 예수나 단월드나 다 눈에 보이지 않는 허상의 것이지 ㅋㅋㅋㅋ\n",
      "    True Label: 0\n",
      "    Prediction (KcELECTRA): 0\n",
      "    Confidence Score (softmax): 0.9796\n",
      "    \n",
      "==================================================\n",
      "\n",
      "    Comment: 라이브는 절대 하지말고... 그러면 욕 안먹어... 립싱크와 퍼포먼스에 집중하도록...\n",
      "    True Label: 0\n",
      "    Prediction (KcELECTRA): 0\n",
      "    Confidence Score (softmax): 0.9550\n",
      "    \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 샘플 데이터 예측결과 확인\n",
    "def visualize_text_samples(sample_data, preds, softmaxs, model_name=\"KcELECTRA\"):\n",
    "    DESC = \"\"\"\n",
    "    Comment: {comment}\n",
    "    True Label: {label}\n",
    "    Prediction ({model_name}): {pred}\n",
    "    Confidence Score (softmax): {softmax}\n",
    "    \"\"\"\n",
    "    for comment, label, pred, softmax in zip(\n",
    "        sample_data['comment'], sample_data['sentiment'], preds, softmaxs\n",
    "    ):\n",
    "        # Format the description\n",
    "        desc = DESC.format(\n",
    "            comment=comment,\n",
    "            label=label,\n",
    "            model_name=model_name,\n",
    "            pred=pred,\n",
    "            softmax=f\"{max(softmax):.4f}\"\n",
    "        )\n",
    "        print(\"=\"*50)\n",
    "        print(desc)\n",
    "    print(\"=\"*50)\n",
    "# 텍스트 출력\n",
    "visualize_text_samples(sample_data, preds, softmaxs, model_name=\"KcELECTRA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone --branch dev https://github.com/OpenXAIProject/pnpxai.git\n",
    "# !pip install -e .\n",
    "# !pip install gradio\n",
    "\n",
    "%cd pnpxai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pnpxai/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Matplotlib created a temporary cache directory at /var/folders/hw/9m3g7fvn4_l3rp2y473km9sm0000gn/T/matplotlib-f7nwwj4b because the default path (/Users/jaesolshin/.matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jaesolshin/Documents/GitHub/youtube_dashboard/pnpxai/tutorials\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import site\n",
    "sys.path.append(site.getsitepackages()[0])\n",
    "\n",
    "import importlib\n",
    "import pnpxai\n",
    "importlib.reload(pnpxai)\n",
    "%cd tutorials\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector and Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AutoExplanation',\n",
       " 'AutoExplanationForImageClassification',\n",
       " 'AutoExplanationForTSClassification',\n",
       " 'AutoExplanationForTextClassification',\n",
       " 'AutoExplanationForVisualQuestionAnswering',\n",
       " 'Experiment',\n",
       " 'XaiRecommender',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'core',\n",
       " 'detect_model_architecture',\n",
       " 'evaluator',\n",
       " 'explainers',\n",
       " 'messages',\n",
       " 'utils']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pnpxai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'pnpxai.core.detector.types.Linear'>, <class 'pnpxai.core.detector.types.Embedding'>}\n"
     ]
    }
   ],
   "source": [
    "from pnpxai import detect_model_architecture\n",
    "\n",
    "detected_modules = detect_model_architecture(model)\n",
    "print(detected_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------  -------------------------------------------------------------------------------------------------------------------------\n",
      "detected_architectures  ['Linear', 'Embedding']\n",
      "explainers              ['Gradient', 'GradientXInput', 'IntegratedGradients', 'KernelShap', 'LRPUniformEpsilon', 'Lime', 'SmoothGrad', 'VarGrad']\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pnpxai import XaiRecommender\n",
    "from pnpxai.core.modality import TextModality\n",
    "\n",
    "recommender = XaiRecommender()\n",
    "recommended = recommender.recommend(modality=TextModality(), model=model)\n",
    "recommended.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainers\n",
    "\n",
    "- A collection of SOTA XAI methods\n",
    "- Easy interface to implement\n",
    "- Various postprocess methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs type: <class 'torch.Tensor'>\n",
      "inputs: tensor([[    2,  1585,  4146,  ...,     0,     0,     0],\n",
      "        [    2,  2741, 31966,  ...,     0,     0,     0],\n",
      "        [    2, 11607, 10196,  ...,     0,     0,     0],\n",
      "        [    2, 29036,  4082,  ...,     0,     0,     0]])\n",
      "attention_mask type: <class 'torch.Tensor'>\n",
      "attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "targets type: <class 'torch.Tensor'>\n",
      "targets: tensor([2, 2, 0, 0], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"inputs type:\", type(inputs))\n",
    "print(\"inputs:\", inputs)\n",
    "print(\"attention_mask type:\", type(attention_mask))\n",
    "print(\"attention_mask:\", attention_mask)\n",
    "print(\"targets type:\", type(preds))\n",
    "print(\"targets:\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequenceClassifierOutput' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m lrp \u001b[38;5;241m=\u001b[39m LRPEpsilonPlus(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# LRP 속성 계산\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m attrs_lrp \u001b[38;5;241m=\u001b[39m \u001b[43mlrp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# model_inputs = {\"input_ids\": inputs, \"attention_mask\": attention_mask}\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# attrs_lrp = lrp.attribute(inputs=model_inputs, targets=preds)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs.shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Documents/GitHub/youtube_dashboard/pnpxai/pnpxai/explainers/zennit/base.py:39\u001b[0m, in \u001b[0;36mset_n_classes_before.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SequenceClassifierOutput' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from pnpxai.explainers import LRPEpsilonPlus\n",
    "\n",
    "# LRP 초기화\n",
    "lrp = LRPEpsilonPlus(model=model)\n",
    "\n",
    "# LRP 속성 계산\n",
    "attrs_lrp = lrp.attribute(inputs=inputs, targets=preds)\n",
    "# model_inputs = {\"input_ids\": inputs, \"attention_mask\": attention_mask}\n",
    "# attrs_lrp = lrp.attribute(inputs=model_inputs, targets=preds)\n",
    "\n",
    "print(\"inputs.shape:\", inputs.shape)\n",
    "print(\"attrs_lrp.shape:\", attrs_lrp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from pnpxai.explainers import LRPEpsilonPlus\n",
    "\n",
    "# 모델 및 토크나이저 로드\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"  # 기본 감정 분석 모델\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 감정 분석 대상 텍스트\n",
    "texts = [\n",
    "    \"I love this product! It's amazing.\",\n",
    "    \"I hate waiting in long lines.\",\n",
    "    \"The movie was okay, not great but not bad either.\",\n",
    "]\n",
    "\n",
    "# 토큰화 및 모델 입력 준비\n",
    "encodings = tokenizer.batch_encode_plus(\n",
    "    texts,\n",
    "    add_special_tokens=True,\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "inputs = encodings[\"input_ids\"].to(device)\n",
    "attention_mask = encodings[\"attention_mask\"].to(device)\n",
    "\n",
    "# 모델 출력 및 예측\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=inputs, attention_mask=attention_mask)\n",
    "    logits = outputs.logits  # 모델 출력\n",
    "    preds = torch.argmax(logits, dim=1)  # 예측값\n",
    "\n",
    "print(\"Predicted classes:\", preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequenceClassifierOutput' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m lrp \u001b[38;5;241m=\u001b[39m LRPEpsilonPlus(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# LRP 속성 계산\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m attrs_lrp \u001b[38;5;241m=\u001b[39m \u001b[43mlrp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# model_inputs = {\"input_ids\": inputs, \"attention_mask\": attention_mask}\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# attrs_lrp = lrp.attribute(inputs=model_inputs, targets=preds)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs.shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Documents/GitHub/youtube_dashboard/pnpxai/pnpxai/explainers/zennit/base.py:39\u001b[0m, in \u001b[0;36mset_n_classes_before.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SequenceClassifierOutput' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from pnpxai.explainers import LRPEpsilonPlus\n",
    "\n",
    "# LRP 초기화\n",
    "lrp = LRPEpsilonPlus(model=model)\n",
    "\n",
    "# LRP 속성 계산\n",
    "attrs_lrp = lrp.attribute(inputs=inputs, targets=preds)\n",
    "# model_inputs = {\"input_ids\": inputs, \"attention_mask\": attention_mask}\n",
    "# attrs_lrp = lrp.attribute(inputs=model_inputs, targets=preds)\n",
    "\n",
    "print(\"inputs.shape:\", inputs.shape)\n",
    "print(\"attrs_lrp.shape:\", attrs_lrp.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
